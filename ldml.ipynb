{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO\n",
    "method prop支持classification\n",
    "q oracle功能未实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,cross_val_predict\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'form_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     train\u001b[39m=\u001b[39mcv[cv\u001b[39m!=\u001b[39mi]\u001b[39m.\u001b[39mdropna()\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      9\u001b[0m     test\u001b[39m=\u001b[39mcv[cv\u001b[39m==\u001b[39mi]\u001b[39m.\u001b[39mdropna()\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mvalues\n\u001b[1;32m---> 10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtrain -  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m   |   test -  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(np\u001b[39m.\u001b[39mbincount(data[form_t][train]), np\u001b[39m.\u001b[39mbincount(data[form_t][test])))\n\u001b[0;32m     11\u001b[0m     cvgroup\u001b[39m.\u001b[39mappend((train,test))\n\u001b[0;32m     13\u001b[0m gammas\u001b[39m=\u001b[39m[\u001b[39m0.25\u001b[39m,\u001b[39m0.5\u001b[39m,\u001b[39m0.75\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'form_t' is not defined"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"D:\\Rworkspace\\LDML\\data.csv\",index_col=0)\n",
    "data.index=data.index-1\n",
    "cv=pd.read_csv(\"D:\\Rworkspace\\LDML\\cvgroup.csv\",index_col=0)\n",
    "cv.index=cv.index-1\n",
    "\n",
    "cvgroup=[]\n",
    "for i in range(1,6):\n",
    "    train=cv[cv!=i].dropna().index.values\n",
    "    test=cv[cv==i].dropna().index.values\n",
    "    print('train -  {}   |   test -  {}'.format(np.bincount(data[form_t][train]), np.bincount(data[form_t][test])))\n",
    "    cvgroup.append((train,test))\n",
    "\n",
    "gammas=[0.25,0.5,0.75]\n",
    "form_x=[\"age\",\"inc\",\"educ\",\"fsize\",\"marr\",\"twoearn\",\"db\",\"pira\",\"hown\" ]\n",
    "form_t=\"p401\"\n",
    "form_y=\"net_tfa\"\n",
    "\n",
    "z=0# test pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_fit_propensities(data, cvgroup, form_x, form_t, method_prop, trim=(0.01,0.99), trim_type='none', normalize=True):\n",
    "    '''cross_val train and predict prop score, then process them'''\n",
    "    #prop=np.zeros(data.shape[0]) \n",
    "    #for train_idx,test_idx in cvgroup:\n",
    "    #    fitted_model=method_prop.fit(data.loc[train_idx][form_x],data.loc[train_idx][form_t])\n",
    "    #    prop[test_idx] = fitted_model.predict(data.loc[test_idx][form_x])\n",
    "\n",
    "    #t为自变量，x为因变量，进行kfold训练和预测\n",
    "    #cv:An iterable that generates (train, test) splits as arrays of indices.\n",
    "    prop=cross_val_predict(method_prop, data[form_x], data[form_t], cv=cvgroup)\n",
    "    \n",
    "    if trim_type == 'drop':\n",
    "        keep = np.logical_and(prop>trim[0],prop<trim[1])\n",
    "        prop[~keep] = 0.5\n",
    "    else:\n",
    "        keep = np.full(data.shape[0],True) #otherwise,keep all rows  \n",
    "        \n",
    "    if trim_type == 'clip':\n",
    "        prop=np.clip(prop,trim[0],trim[1])\n",
    "\n",
    "    #we normalize propensity weights to have mean 1 within each treatment group\n",
    "    #(In each group) P_i=P_i*MEAN(1/P_i),therefore 1/P_i would have mean 1\n",
    "    if normalize:\n",
    "        prop[keep] = data[form_t][keep]*prop[keep]*np.mean(data[form_t][keep]/prop[keep]) + \\\n",
    "                    (1.-data[form_t][keep])*(1.-(1.-prop[keep])*np.mean((1.-data[form_t][keep])/(1.-prop[keep])))\n",
    "    \n",
    "    return prop,keep\n",
    "\n",
    "#测试\n",
    "if True:\n",
    "    method_prop=RandomForestRegressor(n_estimators=100, max_depth=7, max_features=3, min_samples_leaf=3)\n",
    "    result=cross_fit_propensities(data, cvgroup,form_x ,form_t ,method_prop, trim=(0.01,0.99), trim_type='none', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26052574978456966"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def solve_cumsum(vector,c):\n",
    "    '''Return i for i such that summing vector[1:i] is closest to c'''\n",
    "    return pd.Series(abs(np.cumsum(vector)-c)).idxmin()#keep index info\n",
    "#测试\n",
    "solve_cumsum(pd.Series([1,2,3,4],index=[-3,-2,1,2]),2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15504953, 0.19754675, 0.19997058, 0.19754675, 0.15504953])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def density(X, w, x):\n",
    "    '''Estimate the density of data in X at point(s) x with weights w'''\n",
    "    X=np.array(X)\n",
    "    if X.ndim==1:\n",
    "        X=X.reshape(-1,1)\n",
    "    x=np.array([x]).reshape(-1,1)\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=\"scott\").fit(X=X,sample_weight=w)#fit whole curve\n",
    "    return np.exp(kde.score_samples(x))#predict points\n",
    "#测试\n",
    "density(np.array([1,2,3,4,5]),np.ones(5),np.array([1,2,3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>q1</th>\n",
       "      <th>q0</th>\n",
       "      <th>qte</th>\n",
       "      <th>se1</th>\n",
       "      <th>se0</th>\n",
       "      <th>seqte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>-900.0</td>\n",
       "      <td>2302.0</td>\n",
       "      <td>10.682257</td>\n",
       "      <td>1.013900</td>\n",
       "      <td>10.837746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>9649.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>8949.0</td>\n",
       "      <td>13.788891</td>\n",
       "      <td>1.328567</td>\n",
       "      <td>14.201045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>34200.0</td>\n",
       "      <td>13139.0</td>\n",
       "      <td>21061.0</td>\n",
       "      <td>50.884474</td>\n",
       "      <td>38.668499</td>\n",
       "      <td>72.025490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamma       q1       q0      qte        se1        se0      seqte\n",
       "0   0.25   1402.0   -900.0   2302.0  10.682257   1.013900  10.837746\n",
       "1   0.50   9649.0    700.0   8949.0  13.788891   1.328567  14.201045\n",
       "2   0.75  34200.0  13139.0  21061.0  50.884474  38.668499  72.025490"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def est_quantile_ipw(gammas, data, form_x, form_t, form_y, method_prop, \\\n",
    "                    K=5, trim=(0.01,0.99), trim_type='none', normalize=True, avg_eqn=True):\n",
    "    \"\"\"\n",
    "    gammas:list\n",
    "        quantiles to be estimated\n",
    "    data:dataframe \n",
    "        dataset\n",
    "    form_x:list of string\n",
    "        specify columns for x\n",
    "    form_t,form_y:string\n",
    "        specify columns for t,y respectively (only support single treatment variable, so far)\n",
    "    method_prop:estimator implementing ``fit()`` and ``predict()``\n",
    "        method and option for propsperity score estimation, if treatment variable is binary, \n",
    "        then a classification model is acceptable\n",
    "    K:int\n",
    "        kfold_num\n",
    "    trim:list or tuple\n",
    "        upper and lower bound for trim_type=='clip'\n",
    "    trim_type:str\n",
    "        method use to deal with points which has extreme prop score,'drop' or 'clip' or 'none'\n",
    "    normalize:bool\n",
    "        whether to normalize prop score in each treatment group\n",
    "    avg_eqn:bool\n",
    "        if True, estimate q on whole data;\n",
    "        else, estimate q in each fold, then take their mean as final estimation\n",
    "    \"\"\"\n",
    "    #prepare for solve_cumsum \n",
    "    data.sort_values(by=form_y,ascending=True,inplace=True)\n",
    "    data.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    #分层cv\n",
    "    skf = StratifiedKFold(n_splits=K,shuffle=True)\n",
    "    cvgroup=[]\n",
    "    for train, test in skf.split(data, data[form_t]):\n",
    "        cvgroup.append((train,test))#train,test are list, see demo1\n",
    "    \n",
    "    prop,keep = cross_fit_propensities(data, cvgroup, form_x, form_t, method_prop,\\\n",
    "                                    trim=trim, trim_type=trim_type, normalize=normalize)\n",
    "\n",
    "    w1=keep*data[form_t]/prop\n",
    "    w0=keep*(1-data[form_t])/(1-prop)\n",
    "\n",
    "    result=[]\n",
    "    for i,gamma in enumerate(gammas):\n",
    "        if avg_eqn:    \n",
    "            q1=data[form_y][solve_cumsum(w1/sum(keep),gamma)]\n",
    "            q0=data[form_y][solve_cumsum(w0/sum(keep),gamma)]\n",
    "        else:\n",
    "            q1_list=[]\n",
    "            q0_list=[]\n",
    "            for train,test in cvgroup:\n",
    "                # solve_cumsum keeps origin index, so data[form_y] doesn't need to slice\n",
    "                q1_list.append(data[form_y][solve_cumsum(w1[test]/sum(keep[test]),gamma)])\n",
    "                q0_list.append(data[form_y][solve_cumsum(w0[test]/sum(keep[test]),gamma)])\n",
    "            q1=np.mean(q1_list)\n",
    "            q0=np.mean(q0_list)\n",
    "        \n",
    "        # sample value of score function/J, J is estimated by IPW kde at q\n",
    "        keep_t1_mask=np.logical_and(data[form_t]==1,keep)\n",
    "        keep_t0_mask=np.logical_and(data[form_t]==0,keep)\n",
    "        # density result is different from R, more accurated\n",
    "        psi1=(w1[keep]*(data[form_y][keep]<=q1)-gamma)/density(data[form_y][keep_t1_mask], 1/prop[keep_t1_mask], q1)\n",
    "        psi0=(w0[keep]*(data[form_y][keep]<=q0)-gamma)/density(data[form_y][keep_t0_mask], 1/(1-prop[keep_t0_mask]), q0)#???\n",
    "\n",
    "        se1 = np.std(psi1,ddof=1) / np.sqrt(sum(keep))\n",
    "        se0 = np.std(psi0,ddof=1) / np.sqrt(sum(keep))\n",
    "        seqte = np.std(psi1-psi0,ddof=1) / np.sqrt(sum(keep))\n",
    "\n",
    "        result.append(pd.DataFrame({'gamma':gamma,'q1':q1,'q0':q0,'qte':q1-q0,\\\n",
    "                                    'se1':se1,'se0':se0,'seqte':seqte},index=[i]))\n",
    "    \n",
    "    return pd.concat(result,axis=0)\n",
    "    \n",
    "method_prop = linear_model.Lasso(alpha=0.5)\n",
    "result=est_quantile_ipw(gammas, data, form_x, form_t, form_y, method_prop, \\\n",
    "                    K=5, trim=(0.01,0.99), trim_type='clip', normalize=True, avg_eqn=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ldml.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>q1</th>\n",
       "      <th>q0</th>\n",
       "      <th>qte</th>\n",
       "      <th>se1</th>\n",
       "      <th>se0</th>\n",
       "      <th>seqte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>280.0</td>\n",
       "      <td>-775.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>4.265764</td>\n",
       "      <td>6.481763</td>\n",
       "      <td>8.015013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>5552.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>4553.0</td>\n",
       "      <td>36.589348</td>\n",
       "      <td>1.570385</td>\n",
       "      <td>36.916521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>22870.0</td>\n",
       "      <td>15350.0</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>64.956145</td>\n",
       "      <td>15.464816</td>\n",
       "      <td>72.081517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamma       q1       q0     qte        se1        se0      seqte\n",
       "0   0.25    280.0   -775.0  1055.0   4.265764   6.481763   8.015013\n",
       "1   0.50   5552.0    999.0  4553.0  36.589348   1.570385  36.916521\n",
       "2   0.75  22870.0  15350.0  7520.0  64.956145  15.464816  72.081517"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def est_quantile_ldml(gammas, data, form_x, form_t, form_y, method_ipw,method_prop, method_cdf,\\\n",
    "                     K=5, K_ipw=0, semiadaptive=False, trim=(0.01,0.99), trim_type='none',\\\n",
    "                     normalize=True, avg_eqn=True):\n",
    "    \"\"\"\n",
    "    gammas:list\n",
    "        quantiles to be estimated\n",
    "    data:dataframe \n",
    "        dataset\n",
    "    form_x:list of string\n",
    "        specify columns for x\n",
    "    form_t,form_y:string\n",
    "        specify columns for t,y respectively (only support single treatment variable, so far)\n",
    "    method_prop:estimator implementing ``fit()`` and ``predict()``\n",
    "        method and option for propsperity score estimation, if treatment variable is binary, \n",
    "        then a classification model is acceptable\n",
    "    method_ipw,method_cdf:\n",
    "        same as method_prop\n",
    "    K:int\n",
    "        kfold_num\n",
    "    K_ipw:int\n",
    "        folds use to estimate fixed value for localization\n",
    "        default value: np.ceil((K-1)/2)\n",
    "    semiadaptive:bool\n",
    "        if semiadaptive is set to TRUE then we use all out-of-fold data for both IPW and fitting nuisances,\n",
    "        otherwise, out-of-fold data would be spilt into 2 parts for IPW and nuis1 estimation respectively\n",
    "    trim:list or tuple\n",
    "        upper and lower bound for trim_type=='clip'\n",
    "    trim_type:str\n",
    "        method use to deal with points which has extreme prop score,'drop' or 'clip' or 'none'\n",
    "    normalize:bool\n",
    "        whether to normalize prop score in each treatment group\n",
    "    avg_eqn:\n",
    "        if True, estimate q on whole data;\n",
    "        else, estimate q in each fold, then take their mean as final estimation\n",
    "    \"\"\"\n",
    "    #prepare for solve_cumsum \n",
    "    data.sort_values(by=form_y,ascending=True,inplace=True)\n",
    "    data.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=K)\n",
    "    cvgroup=[]\n",
    "    split_cvgroup=[]\n",
    "    for train, test in skf.split(data, data[form_t]):\n",
    "        cvgroup.append((train,test))#train,test are list, see demo1\n",
    "        if not semiadaptive:\n",
    "            l=len(train)\n",
    "            ipw_train=train[:l//2]\n",
    "            nuis1_train=train[l//2:]\n",
    "            split_cvgroup.append((ipw_train,nuis1_train,test))\n",
    "        else:\n",
    "            split_cvgroup.append((copy.deepcopy(train),copy.deepcopy(train),test))#need copy???\n",
    "\n",
    "    #nuis2\n",
    "    prop,keep = cross_fit_propensities(data, cvgroup, form_x, form_t, method_prop,\\\n",
    "                                    trim=trim, trim_type=trim_type, normalize=normalize)\n",
    "    w1=keep*data[form_t]/prop\n",
    "    w0=keep*(1-data[form_t])/(1-prop)\n",
    "\n",
    "    if K_ipw==0:\n",
    "        K_ipw=int(np.ceil((K-1)/2))#向上取整\n",
    "    \n",
    "    result=[]\n",
    "    for i,gamma in enumerate(gammas):\n",
    "        cdf0,cdf1=np.zeros(data.shape[0]),np.zeros(data.shape[0])\n",
    "\n",
    "        for ipw_train,nuis1_train,test in split_cvgroup:\n",
    "            #use take method instead of iloc, for automatiaclly copy\n",
    "            ipw_result = est_quantile_ipw([gamma], data.take(ipw_train), form_x, form_t, form_y, method_ipw, \\\n",
    "                        K=K_ipw, trim=(0.01,0.99), trim_type='clip', normalize=True, avg_eqn=True)\n",
    "\n",
    "            def fit_predict(cdf,q):   \n",
    "                cdf_goal=(data[form_y]<=ipw_result[q][0])\n",
    "                cdf_fit=method_cdf.fit(data.take(nuis1_train),cdf_goal.take(nuis1_train))\n",
    "                cdf[test]=cdf_fit.predict(data.take(test))\n",
    "\n",
    "            fit_predict(cdf1,'q1')\n",
    "            fit_predict(cdf0,'q0')\n",
    "\n",
    "        def ldml_formula(w,cdf,q_num,mask):\n",
    "            if q_num==1:\n",
    "                p=(1.- data[form_t][mask]/prop[mask])\n",
    "            elif q_num==0:\n",
    "                p=(1.-data[form_t][mask])/(1.-prop[mask])\n",
    "\n",
    "            return data[form_y][solve_cumsum(w[mask]/sum(mask),gamma - np.mean(cdf[mask]*p))]\n",
    "            \n",
    "        if avg_eqn:\n",
    "            q1=ldml_formula(w1,cdf1,1,keep)\n",
    "            q0=ldml_formula(w0,cdf0,1,keep)\n",
    "        else:\n",
    "            q1_list,q0_list=[],[]\n",
    "            for ipw_train,nuis1_train,test in split_cvgroup:\n",
    "                q1=ldml_formula(1,keep&test)\n",
    "                q0=ldml_formula(0,keep&test)\n",
    "            q1,q0=np.mean(q1_list),np.mean(q0_list)\n",
    "        \n",
    "        def score_func(w,q,cdf,q_num,mask):\n",
    "            if q_num==1:\n",
    "                p=(1.- data[form_t][mask]/prop[mask])\n",
    "            elif q_num==0:\n",
    "                p=(1.-data[form_t][mask])/(1.-prop[mask])        \n",
    "            return (w[keep] * (data[form_y][keep] <= q)-gamma-cdf[mask]*p)\n",
    "\n",
    "        # sample value of score function/J, J is estimated by IPW kde at q\n",
    "        keep_t1_mask=np.logical_and(data[form_t]==1,keep)\n",
    "        keep_t0_mask=np.logical_and(data[form_t]==0,keep)\n",
    "        psi1=score_func(w1,q1,cdf1,1,keep)/density(data[form_y][keep_t1_mask], 1/prop[keep_t1_mask], q1)\n",
    "        psi0=score_func(w0,q0,cdf0,0,keep)/density(data[form_y][keep_t0_mask], 1/(1-prop[keep_t0_mask]), q0)\n",
    "\n",
    "        se1 = np.std(psi1,ddof=1) / np.sqrt(sum(keep))\n",
    "        se0 = np.std(psi0,ddof=1) / np.sqrt(sum(keep))\n",
    "        seqte = np.std(psi1-psi0,ddof=1) / np.sqrt(sum(keep))\n",
    "        result.append(pd.DataFrame({'gamma':gamma,'q1':q1,'q0':q0,'qte':q1-q0,\\\n",
    "                                    'se1':se1,'se0':se0,'seqte':seqte},index=[i]))\n",
    "    return pd.concat(result,axis=0)\n",
    "\n",
    "method_prop = RandomForestRegressor(n_estimators=50, max_depth=7, max_features=3, min_samples_leaf=3)\n",
    "result=est_quantile_ldml(gammas, data, form_x, form_t, form_y, method_prop,method_prop,method_prop, \\\n",
    "                    K=5, trim=(0.01,0.99), trim_type='clip', normalize=True, avg_eqn=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38\n",
      " 39 40 41 42 43 44 47 48 49] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 45 46]\n",
      "train -  [30  3]   |   test -  [15  2]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 30 31 32 33 34 35 36 37 38\n",
      " 39 40 41 42 43 44 45 46 49] [15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 47 48]\n",
      "train -  [30  3]   |   test -  [15  2]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 45 46 47 48] [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 49]\n",
      "train -  [30  4]   |   test -  [15  1]\n",
      "train -  [28  5]   |   test -  [17]\n",
      "train -  [28  5]   |   test -  [17]\n",
      "train -  [34]   |   test -  [11  5]\n"
     ]
    }
   ],
   "source": [
    "#demo1\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import numpy as np\n",
    "X, y = np.ones((50, 1)), np.hstack(([0] * 45, [1] * 5))\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train, test in skf.split(X, y):\n",
    "    print(train,test)\n",
    "    print('train -  {}   |   test -  {}'.format(np.bincount(y[train]), np.bincount(y[test])))\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "for train, test in kf.split(X, y):\n",
    "    print('train -  {}   |   test -  {}'.format(np.bincount(y[train]), np.bincount(y[test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.85204244e-01, 1.14795704e-01, 5.16221340e-08],\n",
       "       [7.93563244e-01, 2.06436477e-01, 2.79376439e-07]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#demo-classification\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(penalty='l1',solver='liblinear',random_state=0).fit(X, y)\n",
    "print(clf.predict(X[:2, :]))\n",
    "clf.predict_proba(X[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m      3\u001b[0m randomForest \u001b[39m=\u001b[39m RandomForestRegressor(\n\u001b[0;32m      4\u001b[0m     n_estimators\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m, max_features\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, min_samples_leaf\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m model\u001b[39m=\u001b[39mrandomForest\u001b[39m.\u001b[39mfit(X,y)\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mpredict(X))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "#demo-regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "randomForest = RandomForestRegressor(\n",
    "    n_estimators=50, max_depth=7, max_features=3, min_samples_leaf=3)\n",
    "model=randomForest.fit(X,y)\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data generate (Y missing)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def test_data_generator(n=1000,miss_ratio=0.2):\n",
    "    n_miss=int(n*miss_ratio)\n",
    "    n_obs=n-n_miss\n",
    "    x1=np.random.normal(1, 1, n)\n",
    "    x2=np.random.normal(1, 1, n)\n",
    "    x3=np.random.normal(2, 1, n)\n",
    "    y=2*x1+0.5*x2+3*x3+np.random.normal(0, 1, n)\n",
    "    mask=np.append(np.ones(n_obs),np.zeros(n_miss))\n",
    "    np.random.shuffle(mask)\n",
    "    y=np.where(mask==1,y,np.nan)\n",
    "    return pd.DataFrame({'X1':x1,'X2':x2,'X3':x3,'Y':y,'R':mask},index=np.arange(n))\n",
    "\n",
    "data=test_data_generator(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>Y</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.043606</td>\n",
       "      <td>0.071573</td>\n",
       "      <td>2.261580</td>\n",
       "      <td>10.024640</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.710542</td>\n",
       "      <td>-0.324372</td>\n",
       "      <td>1.909698</td>\n",
       "      <td>7.699883</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.777750</td>\n",
       "      <td>1.878143</td>\n",
       "      <td>0.341764</td>\n",
       "      <td>4.540206</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.381029</td>\n",
       "      <td>0.793881</td>\n",
       "      <td>1.751978</td>\n",
       "      <td>5.309508</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.167231</td>\n",
       "      <td>1.551184</td>\n",
       "      <td>1.384395</td>\n",
       "      <td>8.831004</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.783786</td>\n",
       "      <td>0.539434</td>\n",
       "      <td>4.557051</td>\n",
       "      <td>19.407859</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.493483</td>\n",
       "      <td>1.430536</td>\n",
       "      <td>2.962223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.849812</td>\n",
       "      <td>-0.272040</td>\n",
       "      <td>1.661641</td>\n",
       "      <td>9.945182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.991920</td>\n",
       "      <td>-0.292253</td>\n",
       "      <td>1.962195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.907190</td>\n",
       "      <td>0.448751</td>\n",
       "      <td>4.120888</td>\n",
       "      <td>15.674636</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3          Y    R\n",
       "0  1.043606  0.071573  2.261580  10.024640  1.0\n",
       "1  1.710542 -0.324372  1.909698   7.699883  1.0\n",
       "2  1.777750  1.878143  0.341764   4.540206  1.0\n",
       "3  0.381029  0.793881  1.751978   5.309508  1.0\n",
       "4  1.167231  1.551184  1.384395   8.831004  1.0\n",
       "5  2.783786  0.539434  4.557051  19.407859  1.0\n",
       "6  0.493483  1.430536  2.962223        NaN  0.0\n",
       "7  1.849812 -0.272040  1.661641   9.945182  1.0\n",
       "8  1.991920 -0.292253  1.962195        NaN  0.0\n",
       "9  0.907190  0.448751  4.120888  15.674636  1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 64\u001b[0m\n\u001b[0;32m     60\u001b[0m     sigma2\u001b[39m=\u001b[39minv(J0)\u001b[39m.\u001b[39mdot(PSI2)\u001b[39m.\u001b[39mdot(inv(J0))\u001b[39m/\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m (coef,np\u001b[39m.\u001b[39mdiagonal(np\u001b[39m.\u001b[39msqrt(sigma2)),sigma2)\n\u001b[1;32m---> 64\u001b[0m dml(data,[\u001b[39m'\u001b[39;49m\u001b[39mX1\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mX2\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mX3\u001b[39;49m\u001b[39m'\u001b[39;49m],\u001b[39m'\u001b[39;49m\u001b[39mY\u001b[39;49m\u001b[39m'\u001b[39;49m,lm)\n",
      "Cell \u001b[1;32mIn[5], line 32\u001b[0m, in \u001b[0;36mdml\u001b[1;34m(data, form_x, form_y, model, K)\u001b[0m\n\u001b[0;32m     30\u001b[0m train_set\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mtake(train)\u001b[39m.\u001b[39mdropna()\n\u001b[0;32m     31\u001b[0m mu_model\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mfit(train_set[form_x],train_set[form_y]\u001b[39m.\u001b[39mvalues)\n\u001b[1;32m---> 32\u001b[0m mu\u001b[39m=\u001b[39mmu_model\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[0;32m     33\u001b[0m mu_dic[\u001b[39mstr\u001b[39m(i)]\u001b[39m=\u001b[39mmu\u001b[39m#vector\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m#psi_a=XX^T (the notion for X is reverse, i.e. X in python is X^T in paper)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39m#psi_b=X[R(Y-mu)/lambda+mu]\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py38\\lib\\site-packages\\sklearn\\linear_model\\_base.py:355\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    342\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[39m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py38\\lib\\site-packages\\sklearn\\linear_model\\_base.py:338\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    336\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 338\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcoo\u001b[39;49m\u001b[39m\"\u001b[39;49m], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    339\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py38\\lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    534\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 535\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    536\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    537\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py38\\lib\\site-packages\\sklearn\\utils\\validation.py:919\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    914\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    915\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    916\u001b[0m         )\n\u001b[0;32m    918\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 919\u001b[0m         _assert_all_finite(\n\u001b[0;32m    920\u001b[0m             array,\n\u001b[0;32m    921\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    922\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    923\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    924\u001b[0m         )\n\u001b[0;32m    926\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    927\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py38\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "#implementation of DML\n",
    "from numpy.linalg import inv\n",
    "\n",
    "p=0\n",
    "def prepare_data(data):\n",
    "    #我们应当手动插入R变量，符合用户需求\n",
    "    #insert column R\n",
    "    pass\n",
    "\n",
    "def dml(data,form_x,form_y,model,K=5):\n",
    "    skf = StratifiedKFold(n_splits=K,shuffle=True)\n",
    "    cvgroup=[]\n",
    "    for train, test in skf.split(data, data['R']):\n",
    "        cvgroup.append((train,test))\n",
    "    \n",
    "    lambda_dic={}\n",
    "    mu_dic={}\n",
    "    psi_a=pd.DataFrame(0,index=form_x,columns=form_x)\n",
    "    psi_b=pd.Series(0,index=form_x)\n",
    "    for i,(train,test) in enumerate(cvgroup):\n",
    "        X=data.take(test)[form_x]\n",
    "        Y=data.take(test)[form_y].fillna(0).values\n",
    "        R=data.take(test)['R'].values\n",
    "\n",
    "        #lambda=P(R=1|X)\n",
    "        lambda_=data.take(train)['R'].mean()\n",
    "        lambda_dic[str(i)]=lambda_#scalar\n",
    "\n",
    "        #mu=E(Y|X,R=1)\n",
    "        train_set=data.take(train).dropna()\n",
    "        mu_model=model.fit(train_set[form_x],train_set[form_y].values)\n",
    "        mu=mu_model.predict(X)\n",
    "        mu_dic[str(i)]=mu#vector\n",
    "\n",
    "        #psi_a=XX^T (the notion for X is reverse, i.e. X in python is X^T in paper)\n",
    "        #psi_b=X[R(Y-mu)/lambda+mu]\n",
    "        psi_a+=(X.T).dot(X)/len(test)\n",
    "        psi_b+=X.T.dot(R*(Y-mu)/lambda_+mu)/len(test)\n",
    "\n",
    "    coef=inv(psi_a).dot(psi_b)#main para to be estimated\n",
    "    print(coef)\n",
    "\n",
    "    J0=psi_a/K\n",
    "    PSI2=pd.DataFrame(0,index=form_x,columns=form_x)\n",
    "    for i,(train,test) in enumerate(cvgroup):\n",
    "        X=data.take(test)[form_x]\n",
    "        Y=data.take(test)[form_y].fillna(0).values\n",
    "        R=data.take(test)['R'].values\n",
    "\n",
    "        lambda_=lambda_dic[str(i)]\n",
    "        mu=mu_dic[str(i)]\n",
    "        \n",
    "        #notice the 'mul' here, not dot\n",
    "        #right part is vector of shape (n_sample,)\n",
    "        #left part is matrix of shape(form_x, n_sample)\n",
    "        psi=X.T.mul(R*(Y-mu)/lambda_+mu-X.dot(coef))\n",
    "        PSI2=PSI2+psi.dot(psi.T)/len(test)\n",
    "\n",
    "    PSI2=PSI2/K\n",
    "    sigma2=inv(J0).dot(PSI2).dot(inv(J0))/data.shape[0]\n",
    "  \n",
    "    return (coef,np.diagonal(np.sqrt(sigma2)),sigma2)\n",
    "    \n",
    "dml(data,['X1','X2','X3'],'Y',lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_generator(n=1000,miss_ratio=0.2):\n",
    "    n_miss=int(n*miss_ratio)\n",
    "    n_obs=n-n_miss\n",
    "    x1=np.random.normal(1, 1, n)\n",
    "    x2=np.random.normal(1, 1, n)\n",
    "    x3=np.random.normal(2, 1, n)\n",
    "    y=2*x1+0.5*x2+3*x3+np.random.normal(0, 1, n)\n",
    "    mask=np.append(np.ones(n_obs),np.zeros(n_miss))\n",
    "    np.random.shuffle(mask)\n",
    "    x1=np.where(mask==1,x1,np.nan)\n",
    "    return pd.DataFrame({'X1':x1,'X2':x2,'X3':x3,'Y':y,'R':mask},index=np.arange(n))\n",
    "\n",
    "data=test_data_generator(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3, 200) (3, 3)\n",
      "1 (3, 200) (3, 3)\n",
      "2 (3, 200) (3, 3)\n",
      "3 (3, 200) (3, 3)\n",
      "4 (3, 200) (3, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11861\\AppData\\Local\\Temp\\ipykernel_11168\\788730065.py:81: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return (coef,np.diagonal(np.sqrt(sigma2)),sigma2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           0\n",
       " X1  2.039944\n",
       " X2  0.467044\n",
       " X3  2.984812,\n",
       " array([0.03547157, 0.03457739, 0.02377895]),\n",
       " array([[ 0.00125823, -0.00030592, -0.00035328],\n",
       "        [-0.00030592,  0.0011956 , -0.00039493],\n",
       "        [-0.00035328, -0.00039493,  0.00056544]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear missing X continuous\n",
    "\n",
    "p=0\n",
    "def dml(data,form_x,form_z,form_y,model,K=5):\n",
    "    '''\n",
    "    form_x, form_y is str scalar\n",
    "    support one missing variable so far\n",
    "    '''\n",
    "    form_yz=form_z+[form_y]\n",
    "\n",
    "    K=5\n",
    "    skf = StratifiedKFold(n_splits=K,shuffle=True)\n",
    "    cvgroup=[]\n",
    "    for train, test in skf.split(data, data['R']):\n",
    "        cvgroup.append((train,test))\n",
    "    \n",
    "    lambda_dic={}\n",
    "    mu1_dic={}\n",
    "    mu2_dic={}\n",
    "    psi_a=pd.DataFrame(0,index=[form_x]+form_z,columns=[form_x]+form_z)\n",
    "    psi_b=pd.Series(0,index=[form_x]+form_z)\n",
    "  \n",
    "    for i,(train,test) in enumerate(cvgroup):\n",
    "        X=data.take(test)[form_x].fillna(0).values\n",
    "        Y=data.take(test)[form_y].values\n",
    "        Z=data.take(test)[form_z]\n",
    "        R=data.take(test)['R'].values\n",
    "\n",
    "        #lambda=P(R=1|Z,Y)\n",
    "        lambda_=data.take(train)['R'].mean()\n",
    "        lambda_dic[str(i)]=lambda_#scalar\n",
    "\n",
    "        #mu1=E(X|Z,Y,R=1)\n",
    "        #mu2=E(XX^T|Z,Y,R=1)\n",
    "        train_set=data.take(train).dropna()\n",
    "        mu1_model=model.fit(train_set[form_yz],train_set[form_x].values)\n",
    "        mu1=mu1_model.predict(data.take(test)[form_yz])\n",
    "        mu2_model=model.fit(train_set[form_yz],np.power(train_set[form_x].values,2))#new fit would override old fit\n",
    "        mu2=mu2_model.predict(data.take(test)[form_yz])\n",
    "        mu1_dic[str(i)]=mu1#vector\n",
    "        mu2_dic[str(i)]=mu2#vector\n",
    "\n",
    "        left_up=pd.DataFrame(sum(R*(np.power(X,2)-mu2)/lambda_+mu2),index=[form_x],columns=[form_x])\n",
    "        left_down=pd.DataFrame(Z.T.dot(R*(X-mu1)/lambda_+mu1),columns=[form_x])\n",
    "        psi_a=psi_a+pd.concat([pd.concat([left_up,left_down.T],axis=1),\\\n",
    "                            pd.concat([left_down,Z.T.dot(Z)],axis=1)],axis=0)/len(test)\n",
    "    \n",
    "        psi_b=psi_b+pd.concat([pd.Series(sum(Y*(R*(X-mu1)/lambda_+mu1)),index=[form_x]),Z.T.dot(Y)],axis=0)/len(test)\n",
    "  \n",
    "    coef=inv(psi_a).dot(psi_b)#main para to be estimated\n",
    "    coef=pd.DataFrame(coef,index=[form_x]+form_z)\n",
    "    #return coef\n",
    "    beta=coef.loc[form_x][0]\n",
    "    gamma=coef.loc[form_z][0].values\n",
    "\n",
    "    J0=psi_a/K\n",
    "    PSI2=pd.DataFrame(0,index=[form_x]+form_z,columns=[form_x]+form_z)\n",
    "\n",
    "    for i,(train,test) in enumerate(cvgroup):\n",
    "        X=data.take(test)[form_x].fillna(0).values\n",
    "        Y=data.take(test)[form_y].values\n",
    "        Z=data.take(test)[form_z]\n",
    "        R=data.take(test)['R'].values\n",
    "\n",
    "        lambda_=lambda_dic[str(i)]\n",
    "        mu1=mu1_dic[str(i)]\n",
    "        mu2=mu2_dic[str(i)]\n",
    "\n",
    "        up=(R*(X-mu1)/lambda_+mu1)*(Y-Z.dot(gamma))-(R*(np.power(X,2)-mu2)/lambda_+mu2)*beta\n",
    "        down=Z.T.mul(Y-(R*(X-mu1)/lambda_+mu1)*beta-Z.dot(gamma))\n",
    "        up=pd.DataFrame(up,columns=[form_x]).T\n",
    "\n",
    "        psi=pd.concat([up,down],axis=0)\n",
    "        PSI2=PSI2+psi.dot(psi.T)/len(test)\n",
    "\n",
    "    PSI2=PSI2/K\n",
    "    sigma2=inv(J0).dot(PSI2).dot(inv(J0))/data.shape[0]\n",
    "  \n",
    "    return (coef,np.diagonal(np.sqrt(sigma2)),sigma2)\n",
    "\n",
    "dml(data,'X1',['X2','X3'],'Y',randomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data generate (Y missing)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def test_data_generator(n=1000,miss_ratio=0.2):\n",
    "    n_miss=int(n*miss_ratio)\n",
    "    n_obs=n-n_miss\n",
    "    x1=np.random.normal(1, 1, n)\n",
    "    x2=np.random.normal(1, 1, n)\n",
    "    x3=np.random.normal(2, 1, n)\n",
    "    p=1/(1+np.exp(-(2*x1+0.5*x2+3*x3+np.random.normal(0, 0.5, n))))\n",
    "    y=np.random.binomial(1,p)\n",
    "    mask=np.append(np.ones(n_obs),np.zeros(n_miss))\n",
    "    np.random.shuffle(mask)\n",
    "    y=np.where(mask==1,y,np.nan)\n",
    "    return pd.DataFrame({'X1':x1,'X2':x2,'X3':x3,'Y':y,'R':mask},index=np.arange(n))\n",
    "\n",
    "data=test_data_generator(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.81601089, 0.33196636, 3.21246467])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic missing Y\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "def dml(data,form_x,form_y,model,K=5):\n",
    "    #support to use classification method\n",
    "    skf = StratifiedKFold(n_splits=K,shuffle=True)\n",
    "    cvgroup=[]\n",
    "    for train, test in skf.split(data, data['R']):\n",
    "        cvgroup.append((train,test))\n",
    "    \n",
    "    def score_function(coef):\n",
    "        result=np.zeros(len(form_x))\n",
    "        for i,(train,test) in enumerate(cvgroup):\n",
    "            X=data.take(test)[form_x]\n",
    "            Y=data.take(test)[form_y].fillna(0).values\n",
    "            R=data.take(test)['R'].values\n",
    "\n",
    "            #lambda=P(R=1|X)\n",
    "            lambda_=data.take(train)['R'].mean()\n",
    "\n",
    "            #mu=E(Y|X,R=1)\n",
    "            train_set=data.take(train).dropna()\n",
    "            mu_model=model.fit(train_set[form_x],train_set[form_y].values)\n",
    "            mu=mu_model.predict_proba(X)[:,1]#prob of group 1, each row is a 2 element vector\n",
    "            result=result+X.T.dot(R*(Y-mu)/lambda_+mu-1/(1+np.exp(-X.dot(coef))))\n",
    "        return result\n",
    "\n",
    "    result=fsolve(score_function,np.ones(len(form_x)))\n",
    "    return result\n",
    "\n",
    "model=LogisticRegression(C=1000)\n",
    "dml(data,['X1','X2','X3'],'Y',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>Y</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.517342</td>\n",
       "      <td>2.248985</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.007426</td>\n",
       "      <td>1.590435</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.600636</td>\n",
       "      <td>2.032802</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.539362</td>\n",
       "      <td>1.526738</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.846247</td>\n",
       "      <td>1.643792</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.660026</td>\n",
       "      <td>1.408812</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>1.568928</td>\n",
       "      <td>1.098373</td>\n",
       "      <td>2.720613</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.104843</td>\n",
       "      <td>5.149944</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.697529</td>\n",
       "      <td>2.838838</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.693688</td>\n",
       "      <td>1.189403</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3  Y    R\n",
       "0          NaN  0.517342  2.248985  1  0.0\n",
       "1          NaN  1.007426  1.590435  1  0.0\n",
       "2          NaN  1.600636  2.032802  1  0.0\n",
       "3          NaN  1.539362  1.526738  1  0.0\n",
       "4          NaN  0.846247  1.643792  1  0.0\n",
       "...        ...       ...       ... ..  ...\n",
       "2995       NaN  2.660026  1.408812  1  0.0\n",
       "2996  1.568928  1.098373  2.720613  1  1.0\n",
       "2997       NaN  0.104843  5.149944  1  0.0\n",
       "2998       NaN  0.697529  2.838838  1  0.0\n",
       "2999       NaN -0.693688  1.189403  1  0.0\n",
       "\n",
       "[3000 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_data_generator(n=1000,miss_ratio=0.2):\n",
    "    n_miss=int(n*miss_ratio)\n",
    "    n_obs=n-n_miss\n",
    "    x1=np.random.normal(1, 1, n)\n",
    "    x2=np.random.normal(1, 1, n)\n",
    "    x3=np.random.normal(2, 1, n)\n",
    "    p=1/(1+np.exp(-(2*x1+0.5*x2+3*x3+np.random.normal(0, 0.5, n))))\n",
    "    #p=1/(1+np.exp(-(1*x1+1*x2+1*x3+np.random.normal(0, 1, n))))\n",
    "    y=np.random.binomial(1,p)\n",
    "    mask=np.append(np.ones(n_obs),np.zeros(n_miss))\n",
    "    np.random.shuffle(mask)\n",
    "    x1=np.where(mask==1,x1,np.nan)\n",
    "    return pd.DataFrame({'X1':x1,'X2':x2,'X3':x3,'Y':y,'R':mask},index=np.arange(n))\n",
    "\n",
    "data=test_data_generator(3000,0.8)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[2.96015007 0.54438624 3.14001948]\n",
      "1\n",
      "[1.58775421 0.67915339 2.49721628]\n",
      "2\n",
      "[2.25999764 0.54816058 2.76612532]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.26930064, 0.59056673, 2.80112036])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=0\n",
    "from scipy.optimize import fsolve\n",
    "from drf import drf\n",
    "def ldml(data,form_x,form_z,form_y,model_ipw,model_mu1,K=5):    \n",
    "    form_yz=form_z+[form_y]\n",
    "\n",
    "    K=5\n",
    "    skf = StratifiedKFold(n_splits=K,shuffle=True)\n",
    "    cvgroup=[]\n",
    "    for train, test in skf.split(data, data['R']):\n",
    "        cvgroup.append((train,test))\n",
    "    \n",
    "    lambda_dic={}\n",
    "    eta_dic={}\n",
    "\n",
    "    for i,(train,test) in enumerate(cvgroup):\n",
    "        l=len(train)\n",
    "        ipw_train=train[:l//2]#dat1\n",
    "        nuis1_train=train[l//2:]#dat2\n",
    "        #nuis2_train=train\n",
    "        \n",
    "        lambda_=data.take(train)['R'].mean()\n",
    "        \n",
    "        train_set=data.take(train).dropna()\n",
    "        ipw_train_set=data.take(ipw_train).dropna()\n",
    "        nuis1_train_set=data.take(nuis1_train).dropna()\n",
    "        \n",
    "        #model_ipw must be GLM model, have coef_\n",
    "        model_ipw.fit(ipw_train_set[[form_x]+form_z],ipw_train_set[form_y])\n",
    "        theta_ipw=model_ipw.coef_[0]\n",
    "        theta_ipw_intercept=model_ipw.intercept_\n",
    "\n",
    "        #regression model, fxxk\n",
    "        model_mu1.fit(train_set[form_yz],train_set[form_x])\n",
    "        mu1=model_mu1.predict(data.take(test)[form_yz])\n",
    "\n",
    "        DRF = drf(min_node_size = 15, num_trees = 2000, splitting_rule = \"FourierMMD\") #those are the default values\n",
    "        DRF.fit(nuis1_train_set[form_yz],nuis1_train_set[form_x])\n",
    "        mu=DRF.predict(newdata = data.take(test)[form_yz]).weights\n",
    "        \n",
    "        #index:test set; columns:nuis1 train set \n",
    "        part1=data.take(test)[form_z].dot(theta_ipw[1:])+theta_ipw_intercept#constant item\n",
    "        part1=pd.concat([part1]*mu.shape[1],axis=1)\n",
    "        part1.columns=nuis1_train_set.index\n",
    "        part2=theta_ipw[0]*nuis1_train_set[form_x]\n",
    "        part2=pd.concat([part2]*mu.shape[0],axis=1).T\n",
    "        part2.index=test\n",
    "        \n",
    "        expX=1/(1+np.exp(-part1-part2))\n",
    "        X_matrix=pd.concat([nuis1_train_set[form_x]]*mu.shape[0],axis=1).T\n",
    "        X_matrix.index=test\n",
    "        XexpX=X_matrix*expX\n",
    "        mu2=(expX*mu).sum(axis=1)\n",
    "        mu3=(XexpX*mu).sum(axis=1)\n",
    "        Y=data.take(test)[form_y].values\n",
    "        Z=data.take(test)[form_z]\n",
    "        eta=pd.concat([mu1*Y-mu3,Z.apply(lambda x:x*(Y-mu2))],axis=1).T\n",
    "        eta.index=[form_x]+form_z\n",
    "        lambda_dic[str(i)]=lambda_\n",
    "        eta_dic[str(i)]=eta\n",
    "\n",
    "    def score_function(coef):\n",
    "        result=np.zeros(len([form_x]+form_z))\n",
    "        for i,(train,test) in enumerate(cvgroup):\n",
    "            XZ=data.take(test)[[form_x]+form_z].fillna(0)\n",
    "            Y=data.take(test)[form_y].values\n",
    "            R=data.take(test)['R'].values\n",
    "            result=result+XZ.T.dot(R/lambda_dic[str(i)]*(Y-1/(1+np.exp(-XZ.dot(coef)))))\\\n",
    "                    -eta_dic[str(i)].dot(R/lambda_dic[str(i)]-1)\n",
    "        return result\n",
    "\n",
    "    result=fsolve(score_function,np.zeros(len([form_x]+form_z)))\n",
    "    return result\n",
    "\n",
    "rr=np.zeros(3)\n",
    "for i in range(3):\n",
    "    print(i)\n",
    "    r=ldml(data,'X1',['X2','X3'],'Y',model,randomForest)\n",
    "    print(r)\n",
    "    rr+=r\n",
    "rr/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X1      NaN\n",
       "X2      NaN\n",
       "X3      NaN\n",
       "(X1,)   NaN\n",
       "(X2,)   NaN\n",
       "(X3,)   NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0]-p[1].dot(p[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRF forest object\n",
      "Number of trees: 2000 \n",
      "Number of training samples: 1000 \n",
      "[[0.00000000e+00 0.00000000e+00 2.94393581e-03 ... 4.26027189e-04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.14254130e-03 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.27865122e-03 1.31578947e-05 0.00000000e+00 ... 3.57142857e-05\n",
      "  1.81336824e-03 3.32688338e-04]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 4.94653964e-03 ... 1.19047619e-04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.29815658e-03 ... 7.20238095e-05\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.51677693e-04 0.00000000e+00 9.33395018e-04 ... 7.72840385e-03\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from drf import drf\n",
    "\n",
    "# generate data\n",
    "n = 1000\n",
    "p = 10\n",
    "d = 1\n",
    "X = np.random.normal(0, 1, size=(n, p))\n",
    "Y = np.random.normal(0, 1, size=(n, d))\n",
    "Y[:,0] = Y[:,0] + X[:,0] #mean shift of Y1 based on X1\n",
    "#Y[:,1] = Y[:,1] * X[:,1] #variance shift of Y2 based on X2\n",
    "X = pd.DataFrame(X)\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "# fit model\n",
    "DRF = drf(min_node_size = 15, num_trees = 2000, splitting_rule = \"FourierMMD\") #those are the default values\n",
    "DRF.fit(X, Y)\n",
    "DRF.info() #prints variable importance\n",
    "\n",
    "#generate test data\n",
    "X_test = pd.DataFrame(np.random.normal(0, 1, size=(100, p)))\n",
    "\n",
    "# estimated conditional distribution represented via weights\n",
    "out = DRF.predict(newdata = X_test)\n",
    "print(out.weights)\n",
    "\n",
    "# many distributional functionals are implemented and do not need to be manually computed from the weights\n",
    "#out = DRF.predict(newdata = X_test, functional = \"mean\")\n",
    "#print(out.mean)\n",
    "\n",
    "# covariance matrix at a fixed test point\n",
    "#out = DRF.predict(newdata = [0]*p, functional = \"cov\")\n",
    "#print(out.cov[0,:,:])\n",
    "\n",
    "# we can transform the response beforehand to obtain more complicated quantities\n",
    "#out = DRF.predict(newdata = X_test, functional = \"quantile\", transformation = lambda y: (np.sin(y[1]), y[1]*y[2], y[2]**2), quantiles=[0.1, 0.9])\n",
    "#print(out.quantile[0,1,:]) # 0.1 and 0.9 quantiles for first test point in newdata and for the second component of transformed y\n",
    "\n",
    "# we automatically handle factor variables by using one-hot encoding\n",
    "#X['cat'] = np.random.choice(['a', 'b', 'c', 'd', 'e'], n, replace=True)\n",
    "#Y['new'] = np.random.normal(0, 1, size=n) + (X['cat']=='a')\n",
    "#DRF.fit(X, Y)\n",
    "#DRF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.839279</td>\n",
       "      <td>0.834735</td>\n",
       "      <td>0.974269</td>\n",
       "      <td>0.836350</td>\n",
       "      <td>0.368807</td>\n",
       "      <td>-0.793491</td>\n",
       "      <td>-2.755367</td>\n",
       "      <td>-0.560605</td>\n",
       "      <td>0.587878</td>\n",
       "      <td>-0.637156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.121507</td>\n",
       "      <td>1.300074</td>\n",
       "      <td>-0.561701</td>\n",
       "      <td>-2.296089</td>\n",
       "      <td>-0.017208</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>0.106960</td>\n",
       "      <td>-0.572037</td>\n",
       "      <td>-0.696893</td>\n",
       "      <td>-1.541959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.427485</td>\n",
       "      <td>0.978987</td>\n",
       "      <td>-1.724091</td>\n",
       "      <td>0.846568</td>\n",
       "      <td>0.047978</td>\n",
       "      <td>0.454522</td>\n",
       "      <td>0.372446</td>\n",
       "      <td>0.845299</td>\n",
       "      <td>1.855142</td>\n",
       "      <td>1.138090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.326549</td>\n",
       "      <td>0.056731</td>\n",
       "      <td>-0.153277</td>\n",
       "      <td>-0.236694</td>\n",
       "      <td>0.936951</td>\n",
       "      <td>-1.035882</td>\n",
       "      <td>2.439180</td>\n",
       "      <td>-1.065583</td>\n",
       "      <td>0.190394</td>\n",
       "      <td>0.395279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.819528</td>\n",
       "      <td>0.100236</td>\n",
       "      <td>0.159197</td>\n",
       "      <td>-0.182262</td>\n",
       "      <td>-0.853618</td>\n",
       "      <td>-1.247837</td>\n",
       "      <td>2.258070</td>\n",
       "      <td>1.497072</td>\n",
       "      <td>-0.513532</td>\n",
       "      <td>-0.511317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.069951</td>\n",
       "      <td>0.649928</td>\n",
       "      <td>0.424573</td>\n",
       "      <td>-0.478366</td>\n",
       "      <td>1.015995</td>\n",
       "      <td>1.787796</td>\n",
       "      <td>-0.105664</td>\n",
       "      <td>-0.633291</td>\n",
       "      <td>-0.220389</td>\n",
       "      <td>-0.714845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.164187</td>\n",
       "      <td>-0.311909</td>\n",
       "      <td>0.658577</td>\n",
       "      <td>-1.353395</td>\n",
       "      <td>-0.961323</td>\n",
       "      <td>-0.489341</td>\n",
       "      <td>-0.078234</td>\n",
       "      <td>1.324460</td>\n",
       "      <td>0.927713</td>\n",
       "      <td>-1.695038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-1.346707</td>\n",
       "      <td>0.911846</td>\n",
       "      <td>0.658291</td>\n",
       "      <td>1.349356</td>\n",
       "      <td>-1.892918</td>\n",
       "      <td>1.867004</td>\n",
       "      <td>-1.378368</td>\n",
       "      <td>-1.011910</td>\n",
       "      <td>-0.216135</td>\n",
       "      <td>0.086206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.004626</td>\n",
       "      <td>-0.207452</td>\n",
       "      <td>0.587687</td>\n",
       "      <td>-0.362467</td>\n",
       "      <td>0.772684</td>\n",
       "      <td>0.049112</td>\n",
       "      <td>0.318914</td>\n",
       "      <td>-1.272253</td>\n",
       "      <td>0.278229</td>\n",
       "      <td>0.372447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.679280</td>\n",
       "      <td>0.594093</td>\n",
       "      <td>0.683612</td>\n",
       "      <td>-0.761677</td>\n",
       "      <td>-0.505588</td>\n",
       "      <td>1.337972</td>\n",
       "      <td>0.444686</td>\n",
       "      <td>-1.537370</td>\n",
       "      <td>-0.729356</td>\n",
       "      <td>0.473691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.839279  0.834735  0.974269  0.836350  0.368807 -0.793491 -2.755367   \n",
       "1   -2.121507  1.300074 -0.561701 -2.296089 -0.017208  0.432750  0.106960   \n",
       "2   -0.427485  0.978987 -1.724091  0.846568  0.047978  0.454522  0.372446   \n",
       "3   -0.326549  0.056731 -0.153277 -0.236694  0.936951 -1.035882  2.439180   \n",
       "4   -0.819528  0.100236  0.159197 -0.182262 -0.853618 -1.247837  2.258070   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995 -0.069951  0.649928  0.424573 -0.478366  1.015995  1.787796 -0.105664   \n",
       "996 -0.164187 -0.311909  0.658577 -1.353395 -0.961323 -0.489341 -0.078234   \n",
       "997 -1.346707  0.911846  0.658291  1.349356 -1.892918  1.867004 -1.378368   \n",
       "998  1.004626 -0.207452  0.587687 -0.362467  0.772684  0.049112  0.318914   \n",
       "999 -0.679280  0.594093  0.683612 -0.761677 -0.505588  1.337972  0.444686   \n",
       "\n",
       "            7         8         9  \n",
       "0   -0.560605  0.587878 -0.637156  \n",
       "1   -0.572037 -0.696893 -1.541959  \n",
       "2    0.845299  1.855142  1.138090  \n",
       "3   -1.065583  0.190394  0.395279  \n",
       "4    1.497072 -0.513532 -0.511317  \n",
       "..        ...       ...       ...  \n",
       "995 -0.633291 -0.220389 -0.714845  \n",
       "996  1.324460  0.927713 -1.695038  \n",
       "997 -1.011910 -0.216135  0.086206  \n",
       "998 -1.272253  0.278229  0.372447  \n",
       "999 -1.537370 -0.729356  0.473691  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.367141</td>\n",
       "      <td>-0.401015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.938872</td>\n",
       "      <td>-0.144053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.216640</td>\n",
       "      <td>0.522024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.165030</td>\n",
       "      <td>0.038185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.114243</td>\n",
       "      <td>0.049238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.632295</td>\n",
       "      <td>1.250565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.685566</td>\n",
       "      <td>-0.328939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-1.344502</td>\n",
       "      <td>0.185293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2.236488</td>\n",
       "      <td>0.001301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-1.127900</td>\n",
       "      <td>0.061976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0   -0.367141 -0.401015\n",
       "1   -0.938872 -0.144053\n",
       "2   -3.216640  0.522024\n",
       "3   -2.165030  0.038185\n",
       "4   -1.114243  0.049238\n",
       "..        ...       ...\n",
       "995 -0.632295  1.250565\n",
       "996  0.685566 -0.328939\n",
       "997 -1.344502  0.185293\n",
       "998  2.236488  0.001301\n",
       "999 -1.127900  0.061976\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23b11b92dc0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(out.weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.266003</td>\n",
       "      <td>-2.326927</td>\n",
       "      <td>-0.167144</td>\n",
       "      <td>0.453611</td>\n",
       "      <td>0.812868</td>\n",
       "      <td>-1.006852</td>\n",
       "      <td>-0.641708</td>\n",
       "      <td>0.731970</td>\n",
       "      <td>-0.588226</td>\n",
       "      <td>-1.455783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.751619</td>\n",
       "      <td>0.264833</td>\n",
       "      <td>1.360680</td>\n",
       "      <td>-0.362382</td>\n",
       "      <td>0.138664</td>\n",
       "      <td>-1.288945</td>\n",
       "      <td>1.163419</td>\n",
       "      <td>-1.434050</td>\n",
       "      <td>2.383210</td>\n",
       "      <td>0.829570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.817424</td>\n",
       "      <td>1.356615</td>\n",
       "      <td>-0.552565</td>\n",
       "      <td>-1.355037</td>\n",
       "      <td>1.316007</td>\n",
       "      <td>0.081166</td>\n",
       "      <td>0.918712</td>\n",
       "      <td>1.113968</td>\n",
       "      <td>0.981624</td>\n",
       "      <td>-2.022905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.250678</td>\n",
       "      <td>-0.086365</td>\n",
       "      <td>-1.141409</td>\n",
       "      <td>0.497923</td>\n",
       "      <td>-0.013811</td>\n",
       "      <td>-0.207577</td>\n",
       "      <td>0.046045</td>\n",
       "      <td>0.436048</td>\n",
       "      <td>-0.783918</td>\n",
       "      <td>-1.346805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.774400</td>\n",
       "      <td>0.788283</td>\n",
       "      <td>-0.949928</td>\n",
       "      <td>-0.411523</td>\n",
       "      <td>-0.582428</td>\n",
       "      <td>0.793978</td>\n",
       "      <td>0.703432</td>\n",
       "      <td>0.262494</td>\n",
       "      <td>-1.692180</td>\n",
       "      <td>0.417725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.559576</td>\n",
       "      <td>-0.306926</td>\n",
       "      <td>-0.381987</td>\n",
       "      <td>-1.133386</td>\n",
       "      <td>-0.413252</td>\n",
       "      <td>0.162760</td>\n",
       "      <td>0.327102</td>\n",
       "      <td>-0.810778</td>\n",
       "      <td>-0.614363</td>\n",
       "      <td>-1.354231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-1.213105</td>\n",
       "      <td>-1.096146</td>\n",
       "      <td>0.742233</td>\n",
       "      <td>0.941367</td>\n",
       "      <td>-0.054013</td>\n",
       "      <td>0.305591</td>\n",
       "      <td>-0.704571</td>\n",
       "      <td>-0.151366</td>\n",
       "      <td>-1.890847</td>\n",
       "      <td>-0.507476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-1.445236</td>\n",
       "      <td>0.902850</td>\n",
       "      <td>0.298827</td>\n",
       "      <td>1.549959</td>\n",
       "      <td>-0.923840</td>\n",
       "      <td>-1.026148</td>\n",
       "      <td>-1.958187</td>\n",
       "      <td>0.818318</td>\n",
       "      <td>-0.223226</td>\n",
       "      <td>-1.724601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.253199</td>\n",
       "      <td>-1.608266</td>\n",
       "      <td>-0.806056</td>\n",
       "      <td>0.681402</td>\n",
       "      <td>-1.294518</td>\n",
       "      <td>2.019172</td>\n",
       "      <td>0.839666</td>\n",
       "      <td>0.165261</td>\n",
       "      <td>-0.255498</td>\n",
       "      <td>-0.301274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.822420</td>\n",
       "      <td>0.188663</td>\n",
       "      <td>-0.875767</td>\n",
       "      <td>-1.312270</td>\n",
       "      <td>-2.324720</td>\n",
       "      <td>2.990160</td>\n",
       "      <td>-1.527294</td>\n",
       "      <td>-0.701572</td>\n",
       "      <td>-0.915978</td>\n",
       "      <td>-0.343762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.266003 -2.326927 -0.167144  0.453611  0.812868 -1.006852 -0.641708   \n",
       "1   -0.751619  0.264833  1.360680 -0.362382  0.138664 -1.288945  1.163419   \n",
       "2    0.817424  1.356615 -0.552565 -1.355037  1.316007  0.081166  0.918712   \n",
       "3   -0.250678 -0.086365 -1.141409  0.497923 -0.013811 -0.207577  0.046045   \n",
       "4   -0.774400  0.788283 -0.949928 -0.411523 -0.582428  0.793978  0.703432   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  1.559576 -0.306926 -0.381987 -1.133386 -0.413252  0.162760  0.327102   \n",
       "996 -1.213105 -1.096146  0.742233  0.941367 -0.054013  0.305591 -0.704571   \n",
       "997 -1.445236  0.902850  0.298827  1.549959 -0.923840 -1.026148 -1.958187   \n",
       "998  0.253199 -1.608266 -0.806056  0.681402 -1.294518  2.019172  0.839666   \n",
       "999  0.822420  0.188663 -0.875767 -1.312270 -2.324720  2.990160 -1.527294   \n",
       "\n",
       "            7         8         9  \n",
       "0    0.731970 -0.588226 -1.455783  \n",
       "1   -1.434050  2.383210  0.829570  \n",
       "2    1.113968  0.981624 -2.022905  \n",
       "3    0.436048 -0.783918 -1.346805  \n",
       "4    0.262494 -1.692180  0.417725  \n",
       "..        ...       ...       ...  \n",
       "995 -0.810778 -0.614363 -1.354231  \n",
       "996 -0.151366 -1.890847 -0.507476  \n",
       "997  0.818318 -0.223226 -1.724601  \n",
       "998  0.165261 -0.255498 -0.301274  \n",
       "999 -0.701572 -0.915978 -0.343762  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.912819</td>\n",
       "      <td>-2.529923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.999677</td>\n",
       "      <td>-0.200527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.717756</td>\n",
       "      <td>-0.162220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.885987</td>\n",
       "      <td>-0.082575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.494624</td>\n",
       "      <td>-0.539509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2.020581</td>\n",
       "      <td>0.128688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-1.513625</td>\n",
       "      <td>0.063839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-2.208074</td>\n",
       "      <td>-0.002965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.646438</td>\n",
       "      <td>0.023884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.942794</td>\n",
       "      <td>-0.198416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0   -0.912819 -2.529923\n",
       "1   -0.999677 -0.200527\n",
       "2    0.717756 -0.162220\n",
       "3   -1.885987 -0.082575\n",
       "4   -1.494624 -0.539509\n",
       "..        ...       ...\n",
       "995  2.020581  0.128688\n",
       "996 -1.513625  0.063839\n",
       "997 -2.208074 -0.002965\n",
       "998  0.646438  0.023884\n",
       "999  1.942794 -0.198416\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "178729c8f5e9eedf2bae7ea816478a89001acb4e6c66f13ce64ddbee9dd2f878"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
